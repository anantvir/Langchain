from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI
from langchain.load import dumps, loads
from chunking import retriever

# Multi query retrieval prompt
# Multi Query: Different Perspectives
RAG_fusion_template = """You are a helpful assistant that generates multiple search queries based on a single input query. \n
Generate multiple search queries related to: {question} \n
Output (4 queries):"""

prompt_RAG_fusion_template = ChatPromptTemplate.from_template(RAG_fusion_template)

# Returns list of queries ["query1", "query2", "query3", "query4" ...]
chain_generate_queries_for_RAG_fusion = (
    prompt_RAG_fusion_template
    | ChatOpenAI(temperature=0)
    | StrOutputParser()
    | (lambda x : x.split("\n"))
)

def reciprocal_rank_fusion(results : list[list], k = 60):
    """ Reciprocal_rank_fusion that takes multiple lists of ranked documents generated by
        retriever.map() which maps a retriever to each generated query and retrieves corresponding
        documents. k is optional parameter used in the RRF formula for smoothing"""
    
    # Dict holding fused scores of each unique document
    # fused_scores = {'stringified document' : calculated_fusion_score}
    fused_scores = {}

    # Iterate through each list in list of lists i.e list[i]
    for doc_set in results:
        # Iterate through each document in each list i.e list[i][j] with its rank
        for rank, doc in enumerate(doc_set):
            # Convert doc to str to hash it in a dict
            doc_str = dumps(doc)
            # If that document not in fused_scores dictionary, add it with a score 0 which will later be upadted as per ranked fusion algorithm
            if doc_str not in fused_scores:
                fused_scores[doc_str] = 0
            # Retrieve current score of document if any
            previous_doc_score = fused_scores[doc_str]

            # Update the score of 
            fused_scores[doc_str] += 1 / (rank + k)
    print(fused_scores)
    # Sort the documents based on their fused scores in desc. order
    reranked_results = [
        (loads(doc), score) for doc, score in sorted(fused_scores.items(), key = lambda x : x[1], reverse=True)
    ]

    # Return reranked results as a list of tuples where each tuple : (Document in JSON form, fused_Score)
    return reranked_results

chain_RAG_fusion_retrieval = (
    chain_generate_queries_for_RAG_fusion
    | retriever.map()
    | reciprocal_rank_fusion
)

# user_query = "What is task decomposition for LLM agents?"

# docs_tuples = chain_RAG_fusion_retrieval.invoke({"question" : user_query})

# print(docs_tuples)

